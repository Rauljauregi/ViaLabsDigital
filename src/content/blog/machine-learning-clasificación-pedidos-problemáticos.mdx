---
title: "Predecir Pedidos Problem치ticos con Machine Learning: Un Caso para Empresas"
description: >-
    Aprende a predecir pedidos problem치ticos con Machine Learning. Este art칤culo muestra c칩mo implementar XGBoost y SHAP para mejorar la log칤stica, reducir costes y aumentar la satisfacci칩n del cliente.
category: Machine Learning
pubDate: "2025-01-16T16:00:00.000Z"
heroImage: '/images/clasificacion-pedidos-problematicos.webp'
tags:
  - Pyme
  - Machine Learning
  - Caso Pr치ctico
---

En este art칤culo, vamos a abordar un problema com칰n que afecta a empresas con operaciones log칤sticas complejas: **predecir pedidos problem치ticos antes de que ocurran los problemas**. Aunque usamos como ejemplo una empresa que vende miniaturas coleccionables, el enfoque puede aplicarse a cualquier negocio que gestione pedidos en diferentes geograf칤as, productos y tipos de clientes.

## **쯈u칠 es un pedido problem치tico y por qu칠 importa?**
Un pedido problem치tico es aquel que, por diversas razones, genera complicaciones en su procesamiento o entrega. En nuestro caso, hemos identificado tres estados espec칤ficos como "problem치ticos":  

- **Cancelled (Cancelado):** El pedido es anulado antes de completarse, lo que representa una p칠rdida directa.  
- **On Hold (En espera):** El pedido est치 temporalmente bloqueado, lo que afecta la log칤stica y la experiencia del cliente.  
- **Disputed (Disputado):** Existen conflictos relacionados con el pedido, como problemas de facturaci칩n o devoluciones.  

### **Impacto en las empresas:**
1. **P칠rdidas econ칩micas.**  
2. **Problemas log칤sticos y de inventario.**  
3. **Insatisfacci칩n del cliente.**  

> **Cita clave:** Predecir pedidos problem치ticos permite a las empresas tomar decisiones preventivas, mejorando la eficiencia operativa y la experiencia del cliente.


### **Sobre el Dataset y Kaggle**
Usamos un dataset de Kaggle titulado **Sample Sales Data**, dise침ado para pr치cticas en anal칤tica minorista. Este dataset incluye informaci칩n sobre ventas, pedidos, clientes y env칤os. Es ideal para problemas como la predicci칩n, la segmentaci칩n de clientes y el an치lisis de patrones de ventas.

**Cr칠ditos:** El dataset fue creado por Mar칤a Carina Rold치n, consultora de BI, y est치 licenciado bajo Creative Commons.  


## **1. Contexto del negocio**
La empresa vende miniaturas coleccionables, como coches cl치sicos y barcos, con operaciones en m칰ltiples pa칤ses. Sin embargo, un problema recurrente son los **pedidos problem치ticos**, que afectan la log칤stica y generan costes adicionales.  

**Ejemplo de datos en el dataset:**
- **QUANTITYORDERED:** Cantidad de art칤culos solicitados.  
- **PRICEEACH:** Precio por unidad.  
- **PRODUCTLINE:** Categor칤a del producto (e.g., barcos, coches).  
- **DEALSIZE:** Tama침o del pedido (Small, Medium, Large).  

<a href="https://colab.research.google.com/drive/1nIzVsnaOFTjICUl-eiKan8nlJcG71sDB" target="_blank" rel="noopener noreferrer">游녤 Abre el notebook interactivo en Google Colab</a>  
Para ejecutarlo, presiona el bot칩n de "Play" en cada celda o usa <kbd>Shift</kbd> + <kbd>Enter</kbd>.  


춰Vamos a mejorar ese punto para que quede claro en el art칤culo! Aqu칤 tienes una versi칩n m치s detallada y explicativa para el paso de an치lisis y distribuci칩n de datos:


## **2. Cargar y Procesar los Datos**

Explorando el dataset, observamos un **desbalance significativo** entre las dos clases que queremos predecir:  
- **Pedidos no problem치ticos:** Representan la mayor칤a de los pedidos, completados sin incidentes.  
- **Pedidos problem치ticos:** Una minor칤a de pedidos, en estados como "Cancelado", "En espera" o "Disputado".  

Esto se refleja en la **distribuci칩n inicial de clases**, que podemos ver en el gr치fico a continuaci칩n:

<img 
  src="/images/desbalanceo-dataset.png" 
  alt="Distribuci칩n inicial de pedidos: Problem치ticos vs No problem치ticos" 
  title="Distribuci칩n inicial de pedidos: Problem치ticos vs No problem치ticos" 
  style="width: 100%; height: auto; margin: 20px 0; border-radius: 8px;"
/>

### **쯈u칠 significa que los datos est칠n desbalanceados?**
Cuando los datos est치n **desbalanceados**, una de las clases (en este caso, los pedidos problem치ticos) tiene una representaci칩n mucho menor en comparaci칩n con la otra clase (los no problem치ticos). En nuestro caso, por cada pedido problem치tico, hay decenas de pedidos no problem치ticos.  

Esto genera un problema importante para los modelos de Machine Learning, porque:  
1. **Los modelos tienden a favorecer la clase mayoritaria.** Por ejemplo, un modelo podr칤a predecir siempre "No problem치tico" para maximizar su precisi칩n, ignorando completamente la clase minoritaria.  
2. **Dificulta la detecci칩n de casos importantes.** Aunque los pedidos problem치ticos son menos frecuentes, su identificaci칩n es cr칤tica para las operaciones log칤sticas de la empresa.

>**Cita para entenderlo mejor:**  
> Un dataset desbalanceado no solo dificulta el aprendizaje del modelo, sino que puede generar decisiones ineficaces al ignorar los casos m치s importantes.

### **C칩mo abordamos este problema**
Para solucionar el desbalance, aplicamos una t칠cnica llamada **SMOTE (Synthetic Minority Oversampling Technique)**, que genera ejemplos sint칠ticos de la clase minoritaria (pedidos problem치ticos) para equilibrar la proporci칩n de clases. Esto nos permite entrenar un modelo que sea capaz de identificar ambas clases de manera efectiva.

> **Nota:** El desbalanceo es un problema com칰n en datasets del mundo real. Por eso, t칠cnicas como SMOTE son esenciales para mejorar la capacidad predictiva de los modelos.


## **3. Balancear las Clases**
En la etapa inicial, vimos que las clases estaban desbalanceadas, con una mayor칤a de pedidos no problem치ticos y muy pocos pedidos problem치ticos. Este desbalance afecta negativamente la capacidad del modelo para aprender a identificar correctamente ambas clases. 

Para resolver este problema, aplicamos **SMOTE (Synthetic Minority Oversampling Technique)**, una t칠cnica que genera ejemplos sint칠ticos de la clase minoritaria (pedidos problem치ticos) interpolando entre puntos existentes de esta clase.

### **쮺칩mo funciona SMOTE?**
SMOTE crea nuevos ejemplos de la clase minoritaria interpolando entre dos puntos cercanos de esta misma clase. La f칩rmula matem치tica de SMOTE es la siguiente:  

$$
x_{\text{nuevo}} = x_i + \lambda \cdot (x_j - x_i)
$$

donde:
- $x_i$ y $x_j$ son puntos existentes en la clase minoritaria.
- $\lambda \in [0, 1]$ es un valor aleatorio que determina cu치nto nos acercamos o alejamos de $x_i$acia $x_j$.  

Esto tiene como resultado una distribuci칩n equilibrada entre las dos clases, lo que ayuda al modelo de Machine Learning a entrenarse de manera m치s efectiva.  

> **Nota importante:** El balanceo no altera los datos originales, sino que a침ade ejemplos sint칠ticos para mejorar la representatividad de la clase minoritaria.

### **Resultados del balanceo**
Despu칠s de aplicar SMOTE, las clases quedaron perfectamente equilibradas, como se muestra en el gr치fico:

<img 
  src="/images/balanceo-clases.png" 
  alt="Distribuci칩n balanceada de pedidos: Problem치ticos vs No problem치ticos" 
  title="Distribuci칩n balanceada de pedidos: Problem치ticos vs No problem치ticos" 
  style="width: 100%; height: auto; margin: 20px 0; border-radius: 8px;"
/>

Esta nueva distribuci칩n asegura que el modelo pueda aprender de manera equitativa sobre ambas clases, mejorando significativamente su capacidad para identificar pedidos problem치ticos.

> **Para entenderlo mejor:**
> El balanceo de clases es una t칠cnica cr칤tica para resolver problemas de clasificaci칩n desbalanceada, permitiendo que los modelos sean justos y efectivos al predecir casos de importancia operativa.



## **4. Entrenamiento del modelo con XGBoost**

En esta etapa, entrenamos un modelo **XGBoost**, un potente algoritmo basado en 치rboles de decisi칩n. XGBoost es ampliamente utilizado debido a su capacidad para manejar grandes vol칰menes de datos, su velocidad y su flexibilidad para ajustar hiperpar치metros.

### **F칩rmula matem치tica de XGBoost**
XGBoost utiliza un enfoque secuencial para construir 치rboles de decisi칩n y minimizar el error objetivo en cada iteraci칩n. La predicci칩n final para un dato $ x_i $ se calcula como:

$$
\hat{y} = \sum_{t=1}^{T} f_t(x_i) + \gamma
$$

Donde:
- $ f_t(x_i) $: Predicci칩n del 치rbol $ t $-칠simo.
- $ T $: N칰mero total de 치rboles.
- $ \gamma $: Par치metro de regularizaci칩n, que controla la complejidad del modelo para evitar sobreajuste.

El objetivo de XGBoost es minimizar una funci칩n de p칠rdida \( L \) compuesta por dos t칠rminos: el error objetivo y la regularizaci칩n. Matem치ticamente:

$$
L = \sum_{i=1}^{n} \ell(y_i, \hat{y}_i) + \sum_{t=1}^{T} \Omega(f_t)
$$

Donde:
- $ \ell(y_i, \hat{y}_i) $: Funci칩n de p칠rdida, como el logaritmo de p칠rdida (logloss).
- $ \Omega(f_t) $: Regularizaci칩n del 치rbol, que penaliza la complejidad del modelo.

### **Hiperpar치metros usados**
En nuestro modelo, configuramos los siguientes hiperpar치metros:
- **n_estimators:** 100 (n칰mero de 치rboles).
- **max_depth:** 5 (profundidad m치xima de cada 치rbol, para controlar su complejidad).
- **learning_rate:** 0.1 (cu치nto ajustamos los pesos en cada iteraci칩n).
- **subsample:** 0.8 (proporci칩n de datos utilizados para entrenar cada 치rbol).

### **Resultados del modelo**
Despu칠s de entrenar el modelo con nuestros datos balanceados, obtuvimos los siguientes resultados:

#### **Precisi칩n general del modelo:**
$$
\text{Accuracy: } 99.16\%
$$

#### **Reporte de clasificaci칩n:**
| M칠trica      | No problem치tico | Problem치tico | Promedio general |
|--------------|-----------------|--------------|------------------|
| **Precisi칩n**    | 0.99            | 0.99         | 0.99             |
| **Recall**       | 0.99            | 0.99         | 0.99             |
| **F1-Score**     | 0.99            | 0.99         | 0.99             |


### **Reflexi칩n sobre los resultados**
El modelo alcanz칩 una precisi칩n sobresaliente, siendo capaz de clasificar correctamente tanto los pedidos problem치ticos como los no problem치ticos. Esto demuestra que, gracias al balanceo de las clases y el uso de un modelo avanzado como XGBoost, logramos un excelente rendimiento en nuestro problema de clasificaci칩n.

> **Nota clave:** Una precisi칩n del 99.16% significa que el modelo identifica con alta certeza los pedidos problem치ticos, proporcionando insights valiosos para mejorar los procesos empresariales.

### **Pasos en el notebook**
En el notebook, realizamos los siguientes pasos para entrenar el modelo:

```python
# Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)

# Entrenar modelo XGBoost
xgb = XGBClassifier(random_state=42, eval_metric='logloss', n_estimators=100, max_depth=5, learning_rate=0.1, subsample=0.8)
xgb.fit(X_train, y_train)

# Predicciones
y_pred = xgb.predict(X_test)

# Evaluar el modelo
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificaci칩n:")
print(classification_report(y_test, y_pred))
```

**Resultados del notebook:**
```
Accuracy: 0.9916820702402958

Reporte de clasificaci칩n:
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       562
           1       0.99      0.99      0.99       520

    accuracy                           0.99      1082
   macro avg       0.99      0.99      0.99      1082
weighted avg       0.99      0.99      0.99      1082
```


## **5. Interpretaci칩n con SHAP**

Una vez entrenado el modelo, usamos **SHAP** (SHapley Additive exPlanations) para comprender c칩mo cada caracter칤stica afecta las predicciones del modelo. SHAP nos da un desglose claro del impacto de cada variable en las decisiones del modelo, lo que es fundamental para tomar medidas accionables.

### Resultados destacados:
- **MONTH_ID:** Los pedidos realizados en ciertos meses tienen una mayor probabilidad de ser problem치ticos.

> **Exploraci칩n adicional:** Al analizar los datos de entrada, encontramos que los meses de abril, mayo y junio, son m치s propensos a tener problemas, probablemente debido a picos de demanda o congesti칩n log칤stica.

- **COUNTRY:** Pa칤ses como Suecia y USA tienen mayor incidencia en pedidos problem치ticos, posiblemente por diferencias en regulaciones aduaneras, distancias de env칤o, o patrones de demanda.
- **PRODUCTLINE:** Productos como barcos (Ships) y aviones (Planes) tienden a generar m치s problemas, quiz치s porque implican pedidos m치s grandes o m치s complejos de procesar.

### **Gr치fico SHAP:** Importancia de las caracter칤sticas
El siguiente gr치fico muestra las caracter칤sticas m치s importantes seg칰n el modelo. La longitud de cada barra indica cu치nto contribuye una caracter칤stica, en promedio, a las predicciones del modelo.

<img src="/images/shap.png" alt="SHAP Summary Plot: Impacto de las caracter칤sticas" title="SHAP Summary Plot: Impacto de las caracter칤sticas" style="width: 100%; height: auto; margin: 20px 0; border-radius: 8px;" />

#### **Explicaci칩n del gr치fico:**

Las caracter칤sticas en la parte superior, como MONTH_ID y COUNTRY_Sweden, tienen mayor impacto en el resultado del modelo.
Por ejemplo, ciertos valores de MONTH_ID (representando meses espec칤ficos) incrementan la probabilidad de un pedido problem치tico.

#### **쯈u칠 meses son los m치s problem치ticos?**
Analizamos los meses con mayor frecuencia de pedidos problem치ticos. En el notebook, esto se puede hacer con el siguiente fragmento de c칩digo:

```python
Copy
Edit
# Combinar datos reales con etiquetas
X_test['PROBLEMATIC'] = y_test.values

# Agrupar por MONTH_ID para analizar tendencias
problematic_by_month = X_test.groupby('MONTH_ID')['PROBLEMATIC'].mean()

# Visualizar los resultados
problematic_by_month.plot(kind='bar', color='skyblue', title='Porcentaje de pedidos problem치ticos por mes')
plt.ylabel('Porcentaje de pedidos problem치ticos')
plt.xlabel('Mes')
plt.xticks(rotation=0)
plt.show()
```

<img src="/images/meses-problematicos.png" alt="meses m치s problem치ticos en el dataset" title="meses m치s problem치ticos en el dataset" style="width: 100%; height: auto; margin: 20px 0; border-radius: 8px;" />



> **Reflexi칩n sobre SHAP**
>SHAP no solo nos dice qu칠 pedidos tienen problemas, sino tambi칠n por qu칠, permitiendo a las empresas tomar decisiones basadas en datos.

> Al identificar las caracter칤sticas clave que contribuyen a los problemas en los pedidos, las empresas pueden:
>
> - Planificar mejor sus recursos log칤sticos en meses cr칤ticos.
> - Ajustar los tiempos de env칤o o pol칤ticas para ciertos pa칤ses.
> - Revisar la cadena de suministro para productos propensos a problemas, como barcos o aviones.


## **6. Simulaci칩n de predicciones individuales**

Esta secci칩n demuestra c칩mo utilizar el modelo entrenado para realizar predicciones sobre pedidos espec칤ficos, permitiendo evaluar en tiempo real si un nuevo pedido podr칤a ser problem치tico.

**Predicci칩n para un pedido espec칤fico:**  
- **Caracter칤sticas:**  
  - Cantidad pedida: 47.  
  - Precio por unidad: $100.  
  - L칤nea de producto: Motocicletas.  
- **Predicci칩n:** **No problem치tico.**

<img src="/images/simulacion-datos.png" title="simulaci칩n con datos" alt="simulaci칩n con datos" style="width: 100%; height: auto; margin: 20px 0; border-radius: 8px;" />

### **Resultado de la Predicci칩n**
El modelo predice que este pedido es **No problem치tico**, lo cual sugiere que:

- La combinaci칩n de cantidad y precio est치 dentro de rangos normales
- El historial de pedidos similares en esta ubicaci칩n es favorable
- La l칤nea de producto tiene un buen registro de entregas exitosas

### **Interpretaci칩n Pr치ctica**
Esta funcionalidad permite:

- **Evaluaci칩n Preventiva:** Identificar posibles problemas antes de procesar el pedido
- **Gesti칩n de Riesgos:** Tomar medidas proactivas para pedidos identificados como potencialmente problem치ticos
- **Optimizaci칩n de Recursos:** Asignar recursos adicionales solo a pedidos que lo requieran

### **Consideraciones Importantes**

- Las predicciones se basan en patrones hist칩ricos identificados en los datos de entrenamiento
- Es importante mantener el modelo actualizado con nuevos datos para mantener su precisi칩n
- Las predicciones deben usarse como una herramienta de apoyo, no como 칰nico criterio de decisi칩n


## **7. Visualizaci칩n de impacto individual**

### **Explicaci칩n del Gr치fico SHAP (Force Plot)**
Este gr치fico de fuerza SHAP muestra c칩mo diferentes caracter칤sticas contribuyen a la predicci칩n final para un pedido espec칤fico.

<img src="/images/visualizacion.png" title="visualizaci칩n" alt="visualizaci칩n" style="width: 100%; height: auto; margin: 20px 0; border-radius: 8px;" />

#### **Elementos Clave del Gr치fico:**

- **Base value:** El valor central (0) representa la predicci칩n promedio del modelo
- **$f(x)$:** El valor -2.66 es la predicci칩n final para este caso espec칤fico
- **Colores:**

  - **Rojo (higher):** Caracter칤sticas que empujan la predicci칩n hacia valores m치s altos (m치s probabilidad de ser problem치tico)
  - **Azul (lower):** Caracter칤sticas que empujan la predicci칩n hacia valores m치s bajos (menos probabilidad de ser problem치tico)



### **Interpretaci칩n de las Caracter칤sticas:**

#### **Impactos Positivos (Rojo):**

- **COUNTRY_USA** = 1.0: Ser un pedido de Estados Unidos
- **MONTH_ID** = 5.0: Pedidos realizados en mayo


### **Impactos Negativos (Azul):**

- **CITY_Madrid** = 0.0
- **COUNTRY_Sweden** = 0.0
- **CITY_Liverpool** = 0.0
- **PRODUCTLINE_Ships** = 0.0
- **QUANTITYORDERED**
- **CITY_NYC** = 0.0
- **CITY_Boston** = 0.0

Con este modelo, las empresas pueden:  
- 1. Detectar y prevenir problemas antes de que ocurran.  
- 2. Mejorar la log칤stica y reducir costes operativos.  
- 3. Optimizar la experiencia del cliente.  

쯊e gustar칤a implementar una soluci칩n similar en tu negocio? Cont치ctanos en [ViaLabs Digital](https://vialabsdigital.com).  
