---
title: " El futuro del ML es local, y va a revolucionarlo todo \U0001F4CD"
description: " Explora el futuro del machine learning local con nuestra newsletter \U0001F680: ReducciÃ³n de costos, aumento de privacidad y tendencias 2024. Â¡SuscrÃ­bete y domina la revoluciÃ³n AI desde tu dispositivo! \U0001F916âœ¨"
category: Inteligencia Artificial
pubDate: 2024-01-04T23:00:00.000Z
heroImage: /images/machine_learning_local.jpg
tags:
  - Tendencias
  - Empresas
  - Inteligencia Artificial
  - LLM
---

Â¡Feliz viernes de noche de reyes!

MaÃ±ana llegan los Reyes Magos de Oriente, y como sabrÃ¡s, estar al dÃ­a en este torbellino de avances en machine learning es mÃ¡s complicado que los Reyes te regalen el 'Exin Castillos'... Pero aquÃ­ estoy una vez mÃ¡s para compartir contigo las Ãºltimas tendencias que estÃ¡n moldeando el mundo del ML, para traer un poco de luz a la abrumadora avalancha de noticias.

Hoy me gustarÃ­a hablarte sobre una predicciÃ³n que ha hechoÂ Julien Chaumond, CTO de Hugging Face (plataforma de cÃ³digo abierto centrada en inteligencia artificial, conocida por sus bibliotecas y modelos preentrenados).Â La predicciÃ³n es queÂ Â¡El "machine learning local"va a ser tendencia para este 2024!

## Esto lo cambia todo: Machine Learning Local ğŸ¤–

El machine learning, hasta hace poco, era como ese estudiante que estÃ¡ en un internado ( en la nube), alimentado por recursos centralizados yÂ muy costos. Pero, Â¿y si te digo que la tendencia ahora es llevar ese estudiante a "casa"? SÃ­, a los dispositivos de cada uno de nosotros.

Durante 2023, grandes modelos de lenguaje y sus exorbitantes costos de energÃ­a y econÃ³micos han acaparado titulares. Pero mirando al 2024, el enfoque parece estar en un desarrollo y entrenamiento de machine learning "local" para reducir estos costos prohibitivos.

Esta transiciÃ³n se verÃ¡, en parte, impulsada por la adopciÃ³n de Apple Silicon y otros innovadores dispositivos de hardware, asÃ­ como por mejoras en la CPU y dispositivos mÃ³viles. Chaumond ha comentado en LinkedIn: â€œLocal ML is going to be huge.â€

## Apple MLX, Â¿Un Cambio de Paradigma? ğŸ

Recientemente, Apple ha lanzado su framework de machine learning, Apple MLX, desarrollado por su propio equipo de investigaciÃ³n en ML. Este marco permitirÃ¡ a los usuarios de dispositivos Apple utilizar su propio hardware para el procesamiento de inteligencia artificial. Y aquÃ­ viene lo mÃ¡s interesante: este framework es accesible a travÃ©s de librerÃ­as de cÃ³digo abierto como PyPI y GitHub. HAsta ahora se decÃ­a que el gigante tecnolÃ³gico Apple habÃ­ua perdido el tren de la IA ya que no tenÃ­a inversiones en el Cloud como sÃ­ lo tenÃ­an Googleo Microsoft entre otros. Parece que la empresa con mayor capitalizaciÃ³n bursatil del mundo estÃ¡ jugando sus cartas, y puede salirses muy bien...

## Privacidad y Desarrollo de AI ğŸ›¡ï¸

AquÃ­ viene un dato clave: la privacidad. Ben Wood, analista jefe y CMO en CCS Insight, resaltÃ³ la importancia de este enfoque local al procesamiento de inferencias como un paso esencial para los desarrolladores que buscan asegurar la privacidad y mitigar los riesgos de exposiciÃ³n de datos.

En 2023, OpenAI y su ChatGPT levantaron alarmasÂ por un fallo de seguridad. Este tipo de problemas estÃ¡ llevando a organizaciones como Apple a promover el machine learning en el dispositivo como un mÃ©todo vital para retener los datos sensibles en el propio aparato.

## Reduciendo Costos Significativamente ğŸ’°

Los costos de entrenamiento y desarrollo de AI han sido una barrera importante para muchas organizaciones. Entrenar modelos como GPT-3 puede superar los 4 millones de dÃ³lares. Pero en cambioÂ el machine learning local es que al hacerlo en dispositivos, podrÃ­amos evitar esos costosos y amplios requisitos informÃ¡ticos a travÃ©s de mÃ©todos de entrenamiento in situ.

## Un Vistazo a los Grandes Jugadores ğŸ¢

Google y Apple no estÃ¡n solos en este enfoque de inferencia de machine learning en dispositivos locales, sÃ­ Google tambiÃ©n estÃ¡ en esta carreraÂ con sus modelos para moviles. En cuanto a los fabricantes de hardward,Â Qualcomm trabaja arduamente para apoyar la AI en dispositivos a travÃ©s de su Ãºltima generaciÃ³n del platform Snapdragon. Incluso se rumorea que Samsung estÃ¡ explorando estas capacidades en su prÃ³ximo Galaxy S24 Ultra.

Y para todos nosotros, Â¿quÃ© va aÂ significar todo esto? Imagina tener el poder de los modelos de AI mÃ¡s avanzados en la palma de tu mano, sin depender de la nube, con mayor privacidad y a menor costo. Â¿Fascinante, verdad?

Me despido y te recuerdoÂ que lo que aprendemos en este fascinante viaje de la inteligencia artificial es para compartirlo, aplicarlo y, sobre todo, para seguir soÃ±ando en grande. Â¿Podemos hacer un mundo mejor y mÃ¡s justo?

Nos vemos el prÃ³ximo viernes con mÃ¡s novedades y perspectivas transformadoras que te ayudarÃ¡n a entender y a navegar mejor en esta marejada tecnolÃ³gica.

Con afecto y siempre en modo aprendizaje,

RaÃºl JÃ¡uregui www\.vialabsdigital.com

P.D.: Como siempre, no dudes en responder a este email con tus preguntas o comentarios. Â¡Tu curiosidad impulsa esta newsletter!
