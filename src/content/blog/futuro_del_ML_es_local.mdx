---
title: " El futuro del ML es local, y va a revolucionarlo todo \U0001F4CD"
description: " Explora el futuro del machine learning local con nuestra newsletter \U0001F680: Reducción de costos, aumento de privacidad y tendencias 2024. ¡Suscríbete y domina la revolución AI desde tu dispositivo! \U0001F916✨"
category: Inteligencia Artificial
pubDate: 2024-01-04T23:00:00.000Z
heroImage: /images/machine_learning_local.jpg
tags:
  - Tendencias
  - Empresas
  - Inteligencia Artificial
  - LLM
---

¡Feliz viernes de noche de reyes!

Mañana llegan los Reyes Magos de Oriente, y como sabrás, estar al día en este torbellino de avances en machine learning es más complicado que los Reyes te regalen el 'Exin Castillos'... Pero aquí estoy una vez más para compartir contigo las últimas tendencias que están moldeando el mundo del ML, para traer un poco de luz a la abrumadora avalancha de noticias.

Hoy me gustaría hablarte sobre una predicción que ha hecho Julien Chaumond, CTO de Hugging Face (plataforma de código abierto centrada en inteligencia artificial, conocida por sus bibliotecas y modelos preentrenados). La predicción es que ¡El "machine learning local"va a ser tendencia para este 2024!

## Esto lo cambia todo: Machine Learning Local 🤖

El machine learning, hasta hace poco, era como ese estudiante que está en un internado ( en la nube), alimentado por recursos centralizados y muy costos. Pero, ¿y si te digo que la tendencia ahora es llevar ese estudiante a "casa"? Sí, a los dispositivos de cada uno de nosotros.

Durante 2023, grandes modelos de lenguaje y sus exorbitantes costos de energía y económicos han acaparado titulares. Pero mirando al 2024, el enfoque parece estar en un desarrollo y entrenamiento de machine learning "local" para reducir estos costos prohibitivos.

Esta transición se verá, en parte, impulsada por la adopción de Apple Silicon y otros innovadores dispositivos de hardware, así como por mejoras en la CPU y dispositivos móviles. Chaumond ha comentado en LinkedIn: “Local ML is going to be huge.”

## Apple MLX, ¿Un Cambio de Paradigma? 🍏

Recientemente, Apple ha lanzado su framework de machine learning, Apple MLX, desarrollado por su propio equipo de investigación en ML. Este marco permitirá a los usuarios de dispositivos Apple utilizar su propio hardware para el procesamiento de inteligencia artificial. Y aquí viene lo más interesante: este framework es accesible a través de librerías de código abierto como PyPI y GitHub. HAsta ahora se decía que el gigante tecnológico Apple habíua perdido el tren de la IA ya que no tenía inversiones en el Cloud como sí lo tenían Googleo Microsoft entre otros. Parece que la empresa con mayor capitalización bursatil del mundo está jugando sus cartas, y puede salirses muy bien...

## Privacidad y Desarrollo de AI 🛡️

Aquí viene un dato clave: la privacidad. Ben Wood, analista jefe y CMO en CCS Insight, resaltó la importancia de este enfoque local al procesamiento de inferencias como un paso esencial para los desarrolladores que buscan asegurar la privacidad y mitigar los riesgos de exposición de datos.

En 2023, OpenAI y su ChatGPT levantaron alarmas por un fallo de seguridad. Este tipo de problemas está llevando a organizaciones como Apple a promover el machine learning en el dispositivo como un método vital para retener los datos sensibles en el propio aparato.

## Reduciendo Costos Significativamente 💰

Los costos de entrenamiento y desarrollo de AI han sido una barrera importante para muchas organizaciones. Entrenar modelos como GPT-3 puede superar los 4 millones de dólares. Pero en cambio el machine learning local es que al hacerlo en dispositivos, podríamos evitar esos costosos y amplios requisitos informáticos a través de métodos de entrenamiento in situ.

## Un Vistazo a los Grandes Jugadores 🏢

Google y Apple no están solos en este enfoque de inferencia de machine learning en dispositivos locales, sí Google también está en esta carrera con sus modelos para moviles. En cuanto a los fabricantes de hardward, Qualcomm trabaja arduamente para apoyar la AI en dispositivos a través de su última generación del platform Snapdragon. Incluso se rumorea que Samsung está explorando estas capacidades en su próximo Galaxy S24 Ultra.

Y para todos nosotros, ¿qué va a significar todo esto? Imagina tener el poder de los modelos de AI más avanzados en la palma de tu mano, sin depender de la nube, con mayor privacidad y a menor costo. ¿Fascinante, verdad?

Me despido y te recuerdo que lo que aprendemos en este fascinante viaje de la inteligencia artificial es para compartirlo, aplicarlo y, sobre todo, para seguir soñando en grande. ¿Podemos hacer un mundo mejor y más justo?

Nos vemos el próximo viernes con más novedades y perspectivas transformadoras que te ayudarán a entender y a navegar mejor en esta marejada tecnológica.

Con afecto y siempre en modo aprendizaje,

Raúl Jáuregui www\.vialabsdigital.com

P.D.: Como siempre, no dudes en responder a este email con tus preguntas o comentarios. ¡Tu curiosidad impulsa esta newsletter!
