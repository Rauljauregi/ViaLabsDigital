---
title: Explicabilidad vs. Interpretabilidad en IA
description: "Más sobre la compleja relación entre explicabilidad e interpretabilidad en IA. El reto de equilibrar precisión, equidad y comprensión en modelos de machine learning con un enfoque un poco técnico. Para entusiastas y profesionales del ML. \U0001F916\U0001F9E0\U0001F4A1 #MachineLearning #IAExplicable #Interpretabilidad"
category: Deep Learning
pubDate: 2024-02-22T23:00:00.000Z
heroImage: /src/assets/interpretabilidad-explicabilidad-2.webp
tags:
  - Inteligencia Artificial
  - Ética
  - Educación
---

¡Hola!

Hoy me lanzo a otra de nuestras aventuras por el emocionante mundo del machine learning, y tengo un temita entre manos que me ha tenido pegado a artículos y lecturas últimamente: eso de la explicabilidad contra la interpretabilidad en la IA. Resulta que el otro día, charlando con uno de mis mejores colegas en una cena, salió esto a relucir, y me di cuenta de que tenía que aprender un poco más. Aunque ya le había echado un ojo antes en [este artículo](https://mindfulml.vialabsdigital.com/newsletter/post/interpretabilidad-vs-explicabilidad-desvelando-el-enigma-del-machine-learning/), mi amigo me abrió los ojos, y me di cuenta que podía ser más claro y meterle más chicha técnica.

Así que aquí estoy, con nuevos más cosas que aportar y mi infaltable café al lado, listo para  abordar este tema tan importante del ML con un toque más técnico.

¡Vamos allá!

### La Dicotomía entre Explicabilidad e Interpretabilidad

La explicabilidad y interpretabilidad de la inteligencia artificial se han convertido en términos de gran relevancia conforme la IA, y en particular la IA generativa, se integra en las líneas de negocio. La capacidad de generar contenido de forma autónoma por parte de estas tecnologías promete revolucionar todos los sectores empresariales. Sin embargo, con un gran poder se debe tener una gran responsabilidad: la necesidad de que estos modelos sean no solo efectivos sino también comprensibles y justos.

#### Modelos de ML Interpretables: ¿Contradictorio?

La interpretabilidad en el ML se refiere a la capacidad de un modelo para ser entendido en términos de cómo llega a una decisión específica. Por ejemplo, un modelo de regresión logística simple que utiliza cinco entradas (features), cada una ponderada por un coeficiente específico (los pesos $wi$​) y ajustada por un término de bias ($b$), puede parecer a primera vista interpretable debido a su simplicidad matemática: $=∑=1+y=∑i=1n​wi​xi​+b$, donde $y$ es la predicción.

Sin embargo, la simplicidad no es sinónimo de interpretabilidad. Por ejemplo los modelos de redes neuronales profundas, que involucran millones de parámetros, aunque su complejidad estructural puede parecer un obstáculo para la interpretación, estos modelos ofrecen un desempeño superior en tareas complejas, como el mapeo de audio hablado a texto, donde modelos más simples simplemente no pueden competir en términos de precisión y equidad.

#### ¿Interpretable o Explicable? Esa es la Cuestión

La explicabilidad, por otro lado, se inclina más hacia la justificación de las decisiones del modelo en términos comprensibles para los humanos, independientemente de la simplicidad del modelo. Es aquí donde técnicas para la reducción de dimensionalidad y métodos de selección de características como Lasso y Elastic Net entran en juego. Estos métodos pueden simplificar los modelos al reducir el número de características, pero este proceso de simplificación puede, paradójicamente, oscurecer la comprensión intuitiva de cómo las características originales afectan la predicción.

### EEquilibrio

La precisión y la justicia no deben sacrificarse para que el modelo sea más interpretable. Los enfoques tradicionales de ML, aunque más transparentes, a menudo no logran capturar la complejidad de algunos tipos de datos y tareas. En cambio, los modelos de redes neuronales profundas, a pesar de su opacidad, han demostrado ser muy efectivos, aunque su funcionamiento interno pueda ser menos accesible. Es paradódijo ¿verdad?

#### Entendiendo el Porqué Detrás de la IA

Sabemos que hay un montón de cosas sobre los modelos de IA, especialmente esos modelos gigantes que generan texto, que todavía no pillamos del todo. ¿Por qué son tan buenos haciendo lo que hacen? Bueno, aunque todavía los propios científicos están intentando explicarlo. Ya que la gente que investiga estos temas está buscando maneras de no solo hacer que estos modelos sean aún mejores, sino también más fáciles de entender para todos nosotros. La idea es que, mientras más sepamos cómo funcionan, más podemos confiar en ellos.

A medida que nos adentramos más y más en el rollo este del machine learning, es super importante no olvidarnos de mantener las cosas no solo  en el aspecto técnico, sino también en el plano ético. Vamos, que nuestros modelos no solo tienen que ser unos cracks haciendo su trabajo, sino también 'buena gente' en cuanto a ser justos y transparentes se refiere.

Así que, hasta que nos leamos de nuevo por aquí, seguiré curioseando, aprendiendo cosillas y pasándote lo mejor y más interesante que voy descubriendo, del mundillo del machine learning. ¡Que nunca te falte esa chispa de curiosidad y un café que merezca la pena!

Tu amigo  y siempre en modo aprendizaje,

Raúl Jáuregui
